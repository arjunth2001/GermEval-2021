{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e028b3ae-6374-4f47-8cfd-4f8c4b3efaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "tqdm.pandas()\n",
    "import string\n",
    "import re\n",
    "import gensim\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv1D, Embedding, SpatialDropout1D, concatenate\n",
    "from tensorflow.keras.layers import GRU, LSTM,Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import warnings\n",
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from unidecode import unidecode\n",
    "import time\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92be907e-8c9f-473c-9fa0-eedd9a22e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train_ft.csv\")\n",
    "train_aug=pd.read_csv(\"../data/itrain_aug.csv\") # Augmentation ...\n",
    "train=train.append(train_aug[train_aug[\"Sub1_Toxic\"]==1].sample(300),ignore_index=True)\n",
    "train.drop_duplicates('text',inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test=pd.read_csv(\"../data/test_ft.csv\")\n",
    "FEATURES=['readability','!','?',\"caps_vs_length\",\"Partizip II\",\"Präteritum_ich\",\"punc\",\"error\",'Präsens_ich',\"present\",\"future\",'words_vs_unique',\"pos\",\"neg\",\"num_urls\",\"mod\",\"emoji\",\"certainity\",\"uncertainity\",\"num_words\"]\n",
    "features = train[FEATURES].fillna(0)\n",
    "test_features = test[FEATURES].fillna(0)\n",
    "ss = StandardScaler()\n",
    "ss.fit(np.vstack((features, test_features)))\n",
    "features = ss.transform(features)\n",
    "test_features = ss.transform(test_features)\n",
    "y_train = train[[\"Sub1_Toxic\",\"Sub2_Engaging\",\"Sub3_FactClaiming\"]].values\n",
    "X_train = train['text'].fillna(\"etwas\").values\n",
    "X_test = test['text'].fillna(\"etwas\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7f3646-e679-4dd3-a041-8f1bde35c0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17194\n"
     ]
    }
   ],
   "source": [
    "max_features = 17194\n",
    "maxlen = 1000\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(X_train) + list(X_test))\n",
    "X_train_sequence = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequence = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "x_train = sequence.pad_sequences(X_train_sequence, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test_sequence, maxlen=maxlen)\n",
    "print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f42c9f-faef-420c-9893-4554133b2063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e8b093b2cd4a1d9e5489316b5ef47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee32fee1391468b8abd921c60372d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EMBEDDING_FILE_FASTTEXT=\"../data/cc.de.300.vec\"\n",
    "EMBEDDING_FILE_TWITTER=\"../data/glove.txt\"\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index_ft = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in tqdm(open(EMBEDDING_FILE_FASTTEXT,encoding='utf-8')))\n",
    "embeddings_index_tw = dict(get_coefs(*o.strip().split()) for o in tqdm(open(EMBEDDING_FILE_TWITTER,encoding='utf-8')))\n",
    "spell_model = gensim.models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE_FASTTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aff08aab-db32-4af7-969c-6e67d028d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is  based on: Spellchecker using Word2vec by CPMP\n",
    "# https://www.kaggle.com/cpmpml/spell-checker-using-word2vec\n",
    "\n",
    "words = list(spell_model.index_to_key)\n",
    "\n",
    "w_rank = {}\n",
    "for i,word in enumerate(words):\n",
    "    w_rank[word] = i\n",
    "\n",
    "WORDS = w_rank\n",
    "\n",
    "# Use fast text as vocabulary\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def P(word): \n",
    "    \"Probability of `word`.\"\n",
    "    # use inverse of rank as proxy\n",
    "    # returns 0 if the word isn't in the dictionary\n",
    "    return - WORDS.get(word, 0)\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyzäöüß' # Add german\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def singlify(word):\n",
    "    return \"\".join([letter for i,letter in enumerate(word) if i == 0 or letter != word[i-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3a89d6-b60f-4bef-9c3a-aa34a0e44a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b208c59136b6437c8eb278e0a3e5b6d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words,600))\n",
    "\n",
    "something_tw = embeddings_index_tw.get(\"etwas\")\n",
    "something_ft = embeddings_index_ft.get(\"etwas\")\n",
    "\n",
    "something = np.zeros((600,))\n",
    "something[:300,] = something_ft\n",
    "something[300:600,] = something_tw\n",
    "\n",
    "def embed_word(embedding_matrix,i,word):\n",
    "    embedding_vector_ft = embeddings_index_ft.get(word)\n",
    "    if embedding_vector_ft is not None: \n",
    "        embedding_matrix[i,:300] = embedding_vector_ft\n",
    "        embedding_vector_tw = embeddings_index_tw.get(word)\n",
    "        if embedding_vector_tw is not None:\n",
    "            embedding_matrix[i,300:600] = embedding_vector_tw\n",
    "\n",
    "            \n",
    "for word, i in tqdm(word_index.items()):\n",
    "    \n",
    "    if i >= max_features: continue\n",
    "        \n",
    "    if embeddings_index_ft.get(word) is not None:\n",
    "        embed_word(embedding_matrix,i,word)\n",
    "    else:\n",
    "        if len(word) > 20:\n",
    "            embedding_matrix[i] = something\n",
    "        else:\n",
    "            word2 = correction(word)\n",
    "            if embeddings_index_ft.get(word2) is not None:\n",
    "                embed_word(embedding_matrix,i,word2)\n",
    "            else:\n",
    "                word2 = correction(singlify(word))\n",
    "                if embeddings_index_ft.get(word2) is not None:\n",
    "                    embed_word(embedding_matrix,i,word2)\n",
    "                else:\n",
    "                    embedding_matrix[i] = something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47053d86-e4d4-407a-9589-b5db75d20660",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.max_score = 0\n",
    "        self.not_better_count = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=1)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "            if (score > self.max_score):\n",
    "                print(\"*** New High Score (previous: %.6f) \\n\" % self.max_score)\n",
    "                model.save_weights(\"../checkpoints/f_weights.h5\")\n",
    "                self.max_score=score\n",
    "                self.not_better_count = 0\n",
    "            else:\n",
    "                self.not_better_count += 1\n",
    "                if self.not_better_count > 3:\n",
    "                    print(\"Epoch %05d: early stopping, high score = %.6f\" % (epoch,self.max_score))\n",
    "                    self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a521d8-d244-4e87-b9f6-3a17c24fda87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(features,clipvalue=1.,num_filters=40,dropout=0.5,embed_size=600):\n",
    "    features_input = Input(shape=(features.shape[1],))\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    \n",
    "    # Layer 1: concatenated fasttext and glove twitter embeddings.\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "\n",
    "    # Layer 2: SpatialDropout1D(0.5)\n",
    "    x = SpatialDropout1D(dropout)(x)\n",
    "    \n",
    "    # Layer 3: Bidirectional CuDNNLSTM\n",
    "    x = Bidirectional(LSTM(num_filters, return_sequences=True))(x)\n",
    "\n",
    "\n",
    "    # Layer 4: Bidirectional CuDNNGRU\n",
    "    x, x_h, x_c = Bidirectional(GRU(num_filters, return_sequences=True, return_state = True))(x)  \n",
    "    \n",
    "    # Layer 5: A concatenation of the last state, maximum pool, average pool and \n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    x = concatenate([avg_pool, x_h, max_pool,features_input])\n",
    "    \n",
    "    # Layer 6: output dense layer.\n",
    "    outp = Dense(3, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=[inp,features_input], outputs=outp)\n",
    "    import tensorflow as tf\n",
    "    adam = tf.optimizers.Adam(clipvalue=clipvalue)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e9df6-d17d-4672-b407-318f8e93b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "82/82 [==============================] - 69s 787ms/step - loss: 0.6228 - accuracy: 0.3888\n",
      "10/10 [==============================] - 3s 226ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.693396 \n",
      "\n",
      "*** New High Score (previous: 0.000000) \n",
      "\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 63s 771ms/step - loss: 0.5641 - accuracy: 0.5165\n",
      "10/10 [==============================] - 2s 222ms/step\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.727122 \n",
      "\n",
      "*** New High Score (previous: 0.693396) \n",
      "\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 63s 773ms/step - loss: 0.5399 - accuracy: 0.5594\n",
      "10/10 [==============================] - 2s 214ms/step\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.753937 \n",
      "\n",
      "*** New High Score (previous: 0.727122) \n",
      "\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 63s 774ms/step - loss: 0.5239 - accuracy: 0.5571\n",
      "10/10 [==============================] - 2s 218ms/step\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.764445 \n",
      "\n",
      "*** New High Score (previous: 0.753937) \n",
      "\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 63s 772ms/step - loss: 0.5050 - accuracy: 0.5874\n",
      "10/10 [==============================] - 2s 230ms/step\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.765025 \n",
      "\n",
      "*** New High Score (previous: 0.764445) \n",
      "\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 64s 778ms/step - loss: 0.4962 - accuracy: 0.5913\n",
      "10/10 [==============================] - 2s 222ms/step\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.778086 \n",
      "\n",
      "*** New High Score (previous: 0.765025) \n",
      "\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 64s 778ms/step - loss: 0.4834 - accuracy: 0.5916\n",
      "10/10 [==============================] - 2s 224ms/step\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.779181 \n",
      "\n",
      "*** New High Score (previous: 0.778086) \n",
      "\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 64s 780ms/step - loss: 0.4694 - accuracy: 0.6001\n",
      "10/10 [==============================] - 2s 220ms/step\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.782625 \n",
      "\n",
      "*** New High Score (previous: 0.779181) \n",
      "\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 64s 775ms/step - loss: 0.4622 - accuracy: 0.5878\n",
      "10/10 [==============================] - 2s 227ms/step\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.789566 \n",
      "\n",
      "*** New High Score (previous: 0.782625) \n",
      "\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 63s 773ms/step - loss: 0.4453 - accuracy: 0.6093\n",
      "10/10 [==============================] - 2s 215ms/step\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.787807 \n",
      "\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 64s 777ms/step - loss: 0.4289 - accuracy: 0.6273\n",
      "10/10 [==============================] - 2s 224ms/step\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.794716 \n",
      "\n",
      "*** New High Score (previous: 0.789566) \n",
      "\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 63s 771ms/step - loss: 0.4111 - accuracy: 0.6426\n",
      "10/10 [==============================] - 2s 219ms/step\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.789268 \n",
      "\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 64s 776ms/step - loss: 0.3990 - accuracy: 0.6377\n",
      "10/10 [==============================] - 2s 223ms/step\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.789146 \n",
      "\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 63s 771ms/step - loss: 0.3781 - accuracy: 0.6438\n",
      "10/10 [==============================] - 2s 229ms/step\n",
      "\n",
      " ROC-AUC - epoch: 14 - score: 0.783309 \n",
      "\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 64s 775ms/step - loss: 0.3668 - accuracy: 0.6476\n",
      "10/10 [==============================] - 2s 223ms/step\n",
      "\n",
      " ROC-AUC - epoch: 15 - score: 0.784794 \n",
      "\n",
      "Epoch 00014: early stopping, high score = 0.794716\n",
      "11/11 [==============================] - 3s 230ms/step\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 68s 772ms/step - loss: 0.6294 - accuracy: 0.4133\n",
      "10/10 [==============================] - 3s 213ms/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.674697 \n",
      "\n",
      "*** New High Score (previous: 0.000000) \n",
      "\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 63s 768ms/step - loss: 0.5531 - accuracy: 0.5376\n",
      "10/10 [==============================] - 2s 208ms/step\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.715251 \n",
      "\n",
      "*** New High Score (previous: 0.674697) \n",
      "\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 63s 763ms/step - loss: 0.5316 - accuracy: 0.5602\n",
      "10/10 [==============================] - 2s 223ms/step\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.725467 \n",
      "\n",
      "*** New High Score (previous: 0.715251) \n",
      "\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 63s 763ms/step - loss: 0.5148 - accuracy: 0.5633\n",
      "10/10 [==============================] - 2s 221ms/step\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.730794 \n",
      "\n",
      "*** New High Score (previous: 0.725467) \n",
      "\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 62s 762ms/step - loss: 0.4976 - accuracy: 0.5629\n",
      "10/10 [==============================] - 2s 229ms/step\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.748752 \n",
      "\n",
      "*** New High Score (previous: 0.730794) \n",
      "\n",
      "Epoch 6/100\n",
      "70/82 [========================>.....] - ETA: 9s - loss: 0.4840 - accuracy: 0.5857 "
     ]
    }
   ],
   "source": [
    "del spell_model\n",
    "del embeddings_index_ft\n",
    "del embeddings_index_tw\n",
    "\n",
    "model = get_model(features)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "\n",
    "num_folds = 10 \n",
    "\n",
    "predict = np.zeros((test.shape[0],3))\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=239)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    \n",
    "    kfold_y_train,kfold_y_test = y_train[train_index], y_train[test_index]\n",
    "    kfold_X_train = x_train[train_index]\n",
    "    kfold_X_features = features[train_index]\n",
    "    kfold_X_valid = x_train[test_index]\n",
    "    kfold_X_valid_features = features[test_index] \n",
    "    \n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = get_model(features)\n",
    "    \n",
    "    ra_val = RocAucEvaluation(validation_data=([kfold_X_valid,kfold_X_valid_features], kfold_y_test), interval = 1)\n",
    "    \n",
    "    model.fit([kfold_X_train,kfold_X_features], kfold_y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "             callbacks = [ra_val])\n",
    "    gc.collect()\n",
    "    model.load_weights(\"../checkpoints/f_weights.h5\")\n",
    "    \n",
    "    predict += model.predict([x_test,test_features], batch_size=batch_size,verbose=1) / num_folds\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b371ea-1691-4602-95d0-a96527804a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"1\",\"2\",\"3\"]]=predict\n",
    "test[[\"1\",\"2\",\"3\"]].to_csv(\"../submissions/gru-fasttext-p.csv\")\n",
    "test[[\"1\",\"2\",\"3\"]]=predict.round(0).astype(int)\n",
    "test[[\"1\",\"2\",\"3\"]].to_csv(\"../submissions/gru-fasttext.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
